{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astro 528, Lab 7, Exercise 2\n",
    "## Parallelization for Cluster using Distributed-Memory Model\n",
    "\n",
    "In this lab exercise, we'll perform the calculations very similar to those of exercise 2 of lab 5.  However, instead of using a multi-core workstation, we will [run the calculations on the ICDS Roar Collab cluster](https://www.icds.psu.edu/roar-collab-user-guide/) using a distributed memory model.  \n",
    "\n",
    "You're welcome to run this notebook one cell at a time as in other labs to see how it works.  However, the main point of this lab is to see how to run such a calculation in parallel over multiple processor cores that are not necessarily on the same processor.  Therefore, you'll use the command line interface to submit the jobs [ex2.pbs](https://github.com/PsuAstro528/lab7-start/blob/main/ex2.slurm).  Follow the instructions in the [lab's README](https://github.com/PsuAstro528/lab7-start/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:42.438000-05:00",
     "start_time": "2019-02-25T07:17:40.141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/storage/work/ebf11/Teach/Astro528/Fall2023/lab7-start`\n"
     ]
    }
   ],
   "source": [
    "# Just in case you're running this from JupyterLab\n",
    "import Pkg\n",
    "Pkg.UPDATED_REGISTRY_THIS_SESSION[] = true   \n",
    "Pkg.activate(\".\")\n",
    "# Shouldn't need to instantiate the project, since you'll have already run as part of exercise 1.  But I'll default to running it just in case.\n",
    "Pkg.instantiate()\n",
    "# Again, just being extra careful to make sure everything is precompiled by delegator process before assigning work to worker proceses\n",
    "Pkg.precompile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, packages are installed to disk and the Roar Collab nodes all see the same file systems, so you only want to run `instantiate` and `precompile` once on the delegator process.\n",
    "\n",
    "We'll load the CSV and DataFrames packages that only need to be loaded by the delegator process.\n",
    "Then we'll load Julia's `Distributed` module that provides much of the needed functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:49.984000-05:00",
     "start_time": "2019-02-25T07:17:40.143Z"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Package CpuId not found in current path.\n- Run `import Pkg; Pkg.add(\"CpuId\")` to install the CpuId package.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package CpuId not found in current path.\n- Run `import Pkg; Pkg.add(\"CpuId\")` to install the CpuId package.",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ ./loading.jl:1630 [inlined]",
      " [2] macro expansion",
      "   @ ./lock.jl:267 [inlined]",
      " [3] require(into::Module, mod::Symbol)",
      "   @ Base ./loading.jl:1611"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, CpuId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting setup for parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Julia is using 1 workers.\n"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "#using ClusterManagers  # For simplifying adding processors in SLURM jobs\n",
    "println(\"# Julia is using \", nworkers(), \" workers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mSince there's only one processor, I'm guessing you're running this from inside JupyterLab rather than a dedicated slurm job.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Main In[4]:3\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Int64}:\n",
       " 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if nworkers() == 1\n",
    "    if haskey(ENV,\"SLURM_NTASKS_PER_NODE\")\n",
    "        @warn \"Since there's only one processor, I'm guessing you're running this from inside JupyterLab rather than a dedicated slurm job.\"\n",
    "        cores_per_node = parse(Int,ENV[\"SLURM_NTASKS_PER_NODE\"])\n",
    "        addprocs(cores_per_node)\n",
    "    elseif haskey(ENV,\"GITHUB_ACTION\")   \n",
    "        @warn \"Not adding any worker processes since running on GitHub.\"\n",
    "    else \n",
    "        @warn \"It appears this is not running on Roar Collab.  So we'll add one worker process for each physical core.\"\n",
    "        addprocs(cpucores())\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this inside a Jupyter notebook, you are likely to see a warning about srun not honoring the value of ``--ntasks-per-node`.  You can ignore that for now.  (If you're itnerested, it's because the BYOE Jupyter environment is allocating multiple cores on one node, rather than multiple nodes each with one process.  But since we're demosntrating parallel programming ofr a distributed memory model, we're going to code as if they might not all have access to a shared memory system.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Now Julia is using 1 workers.\n"
     ]
    }
   ],
   "source": [
    "println(\"# Now Julia is using \", nworkers(), \" workers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages and modules\n",
    "\n",
    "Now, we can start loading other packages that we'll be using.  Since we want the packages to be in scope on each worker, then we need to add the `@everywhere` macro in front of the using statement.  \n",
    "\n",
    "#Before we can do that we need to activate the project on each of the workers, so they know that they can use the packages in Project.toml.  We don't need to install or instantiate on each worker, since those write files to disk and all the workers have access to the same filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:58.903000-05:00",
     "start_time": "2019-02-25T07:17:40.148Z"
    }
   },
   "outputs": [],
   "source": [
    "#@everywhere using Pkg\n",
    "#@everywhere Pkg.UPDATED_REGISTRY_THIS_SESSION[] = true   # Tell Julia package manager not to download an updated registry for\n",
    "#@everywhere Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:01.598000-05:00",
     "start_time": "2019-02-25T07:17:40.150Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere using Distributions\n",
    "@everywhere using DistributedArrays\n",
    "@everywhere using ParallelDataTransfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, I've written several functions that will be used to generate simulated spectra.  This serves a couple of purposes.\n",
    "First, you'll use the code in the exercise, so you have a calculation that's big enough to be worth parallelizing.  For the purposes of this exercise, it's not essential that you review the code I provided in `.jl` files.  However, the second purpose of providing this is to demonstrate several of the programming patterns that we've discussed in class.  For example, the code in the `lab7` module\n",
    "- is in the form of several small functions, each which does one specific task.  \n",
    "- has been moved out of the Jupyter notebook and into `.jl` files in the `src` directory.\n",
    "- creates custom types for objectstaht represent spectra and a convolution kernel.\n",
    "- uses [abstract types](https://docs.julialang.org/en/v1/manual/types/#Abstract-Types-1), [parametric types](https://docs.julialang.org/en/v1/manual/types/#Parametric-Types-1), and type-stable functions. \n",
    "- has been  put into a Julia [module](https://docs.julialang.org/en/v1/manual/modules/index.html), so that it can be easily loaded and so as to limit potential for namespace conflicts.\n",
    "\n",
    "You don't need to read all of this code right now.  But, when you're writing code for your class project, you're likely to want to make use of some of these same programming patterns. So, it may be useful to refer back to this code later to help see examples of how to apply these design patterns in practice.  \n",
    "        \n",
    "For now, let's include just the file that has the code for the `lab7` module.  `src/lab7.jl` includes the code from the other files.  We'll preface it with `@everywhere`, since we want all of the processors to be able to make use of these function and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.022000-05:00",
     "start_time": "2019-02-25T07:17:40.153Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere include(\"src/lab7.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll bring that module into scope.  Note that since this is not a package, we need to include a `.` to tell Julia that it should load a module in the current namespace, rather than needing to load a package from among those in the general Julia registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.023000-05:00",
     "start_time": "2019-02-25T07:17:40.155Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere using .lab7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data to be analyzed\n",
    "In this exercise, we're going to create a model spectrum consisting of continuum, stellar absorption lines, telluric absorption lines.  \n",
    "The `lab7` module provides a `SimulatedSpectrum` type, but we'll need to initialize a variable with some specific parameter values.  The function does that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.506000-05:00",
     "start_time": "2019-02-25T07:17:40.157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_spectrum_object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Create an object that provides a model for the raw spetrum (i.e., before entering the telescope)\"\n",
    "function make_spectrum_object(;lambda_min = 4500, lambda_max = 7500, flux_scale = 1.0,\n",
    "        num_star_lines = 200, num_telluric_lines = 100, limit_line_effect = 10.0)\n",
    "\n",
    "    continuum_param = flux_scale .* [1.0, 1e-5, -2e-8]\n",
    "    \n",
    "    star_line_locs = rand(Uniform(lambda_min,lambda_max),num_star_lines)\n",
    "    star_line_widths = fill(1.0,num_star_lines)\n",
    "    star_line_depths = rand(Uniform(0,1.0),num_star_lines)\n",
    "    \n",
    "    telluric_line_locs = rand(Uniform(lambda_min,lambda_max),num_telluric_lines)\n",
    "    telluric_line_widths = fill(0.2,num_telluric_lines)\n",
    "    telluric_line_depths = rand(Uniform(0,0.4),num_telluric_lines)\n",
    "\n",
    "    SimulatedSpectrum(star_line_locs,star_line_widths,star_line_depths,telluric_line_locs,telluric_line_widths,telluric_line_depths,continuum_param=continuum_param,lambda_mid=0.5*(lambda_min+lambda_max),limit_line_effect=limit_line_effect)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we: \n",
    "1. create a set of wavelengths to observe the spectrum at, \n",
    "2. call the function above to create a spectrum object, \n",
    "3. create an object containing a model for the point spread function, and \n",
    "4. create an object that can compute the convolution of our spectral model with the point spread function model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:05.032000-05:00",
     "start_time": "2019-02-25T07:17:40.159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolvedSpectrum{SimulatedSpectrum{Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}, GaussianMixtureConvolutionKernel{Float64, Float64}}(SimulatedSpectrum{Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}([7154.882994955389, 4704.845637862227, 5826.474964912281, 7400.536830749161, 5803.686524661388, 5413.13802043939, 6221.08046413957, 7345.235539086247, 7130.1938039127, 5694.4433132431295  …  4766.240455835495, 4891.836388257195, 5272.325621484325, 6067.361336056703, 7217.593666768591, 6309.730722147076, 6263.261865957172, 5055.754457562454, 5049.349811317647, 5691.535157022617], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.1456233114959007, 0.5465976703889676, 0.40335960685717887, 0.4706217041381907, 0.022898422561114185, 0.877684072703645, 0.422030490345612, 0.6187443799767288, 0.18255782395582976, 0.13201398182402424  …  0.2672248730231923, 0.8864602417650028, 0.7490744790284204, 0.5150895012186185, 0.681439378462789, 0.42649410600645443, 0.27769094257822, 0.415468197819595, 0.46655130004736645, 0.9223496700195876], [4633.897298162223, 5192.617198853451, 4623.01307831644, 5703.975046468496, 4740.177655980362, 6878.3695614672415, 6110.156265108091, 6744.297368687693, 6233.333437844757, 4502.1974323878485  …  7324.911361265376, 6712.288879589896, 5729.315135784145, 5295.290334744622, 5006.946636097901, 6820.469022223548, 6022.308495667416, 4684.795558296461, 6853.442079072966, 4925.394469665238], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2  …  0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.25477720230297074, 0.00496774752581124, 0.33652819626925345, 0.05776358075158701, 0.38922142111907854, 0.27508750691066364, 0.24020054608709202, 0.25678370434988096, 0.28522858915633104, 0.14645255006029134  …  0.2868918640575197, 0.30318141665224263, 0.11644624829353943, 0.02701994981976763, 0.21544363074365724, 0.054962453980972506, 0.19641725918708142, 0.06997421643816493, 0.3051459131402284, 0.08392180592464449], [1.0, 1.0e-5, -2.0e-8], 0.0, 6000.0, 10.0), GaussianMixtureConvolutionKernel{Float64, Float64}(Normal{Float64}[Normal{Float64}(μ=0.0, σ=0.5), Normal{Float64}(μ=0.0, σ=1.0), Normal{Float64}(μ=0.0, σ=2.0)], [0.8, 0.15, 0.05], 1.0000000143325827, 10.0), 10.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.  Pick range of of wavelength to work on.\n",
    "lambda_min = 4500.0\n",
    "lambda_max = 7500.0\n",
    "# You may want to adjust the num_lambda to make things more/less computationally intensive\n",
    "num_lambda = 128*1024\n",
    "lambdas = collect(range(lambda_min,stop=lambda_max, length=num_lambda));\n",
    "\n",
    "# 2.  Create a model  spectrum that we'll analyze below\n",
    "raw_spectrum = make_spectrum_object(lambda_min=lambda_min,lambda_max=lambda_max)\n",
    "\n",
    "# 3.  Create a model for the point spread function (PSF)\n",
    "psf_widths  = [0.5, 1.0, 2.0]\n",
    "psf_weights = [0.8, 0.15, 0.05]\n",
    "psf_model = GaussianMixtureConvolutionKernel(psf_widths,psf_weights)\n",
    "\n",
    "# 4. Create a model for the the convolution of thte raw spectrum with the PDF model\n",
    "conv_spectrum = ConvolvedSpectrum(raw_spectrum,psf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking serial code\n",
    "\n",
    "*If the current job has just one worker process,* then we'll benchmark the calculation of this spectrum on a single processor.  Based on performance results from lab 5, we'll make use of Julia's [dot syntax](https://docs.julialang.org/en/v1/manual/functions/#man-vectorized-1) to [\"broadcast\" and \"fuse\"](https://docs.julialang.org/en/v1/base/arrays/#Broadcast-and-vectorization-1) the array operation.    We'll run it just a few times (rather than using `@btime`).\n",
    "Since the rest of the notebook is meant for distributed computing, we'll tell it to exit here if there's only a single worker.  Before we do, we'll flush the buffer, so any messages are written to `STDOUT` before the kernel exits.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:05.217000-05:00",
     "start_time": "2019-02-25T07:17:40.160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18.221337 seconds (38.52 M allocations: 2.913 GiB, 1.94% gc time, 12.03% compilation time)\n",
      " 15.996442 seconds (34.10 M allocations: 2.642 GiB, 1.45% gc time)\n"
     ]
    }
   ],
   "source": [
    "num_runs = 2\n",
    "if nworkers() == 1    \n",
    "    for i in 1:num_runs @time conv_spectrum.(lambdas); end\n",
    "    flush(stdout) # flush buffer before the kernel exits\n",
    "    sleep(1)      # wait for one second just to make sure\n",
    "    if haskey(ENV,\"GITHUB_ACTION\")                                               \n",
    "        exit(0)      # Don't try to do parallel work in GitHub actions\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this in a Jupyter notebook and got a message about the kernel dieing, don't worry.  We used the `exit` command to cause the julia kernel to exit.  If you're in the notebook server and want to keep going, then you can rerun the previous cells above, but comment out hte `exit` command.  Just be aware that this could make things take a while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Arrays\n",
    "Here, we want to spread the work over processor cores than are not necessarily on the same node, so we need to use a [distributed memory system](https://en.wikipedia.org/wiki/Distributed_memory).  This would be necessary if you wanted your job to run on more cores than are available on a single node.  It could also be useful if you wanted to increase the chances that the scheduler starts your job more quickly, since asking for several processors cores that don't need to be on the same node is easier to accommodate than asking for the same number of cores on a single node.  Here we'll use Julia's [DistributedArrays.jl](https://juliaparallel.github.io/DistributedArrays.jl/latest/index.html) package to make programming for distributed memory systems relatively easy.  \n",
    "\n",
    "Here we'll create a distributed array by simply applying `distribute` to our existing array of wavelengths.  (Remember that we could initialize a `DArray` more efficiently be letting each workers initializes its own data.  For convenience functions like `dzeros`, `dones`, `drand`, `drandn` and `dfill` act similarly to their counterparts without a `d` prefix, but create DArrays instead of regular Arrays.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:07.340000-05:00",
     "start_time": "2019-02-25T07:17:40.163Z"
    }
   },
   "outputs": [],
   "source": [
    "lambdas_dist = distribute(lambdas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first time we call a function, it takes some extra time and memory to compile it.  So let's do that again, this time benchmarking the `distribute` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:07.393000-05:00",
     "start_time": "2019-02-25T07:17:40.165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to distribute.\n",
      "  0.002528 seconds (195 allocations: 1.009 MiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to distribute.\")\n",
    "@time lambdas_dist = distribute(lambdas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will apply `map` to a `lambda_dist`, which is a `DArray`.  `map` will parallelize the calculation and return the results in a `DArray`.  Each worker operates on the subset of the array that is local to that worker process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:09.082000-05:00",
     "start_time": "2019-02-25T07:17:40.167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to map(...).\n",
      " 18.139534 seconds (590.30 k allocations: 39.553 MiB, 0.07% gc time, 1.66% compilation time)\n",
      " 15.884175 seconds (23.06 k allocations: 1.545 MiB, 0.34% compilation time)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to map(...).\")\n",
    "for i in 1:num_runs \n",
    "    @time map(conv_spectrum,lambdas_dist) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we left the results with the workers, rather than copying the results back to the delegator process.\n",
    "In the cell below, we will call `collect` the data in order to copy all the data back to to the delegator process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:09.082000-05:00",
     "start_time": "2019-02-25T07:17:40.167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to collect(map(...)).\n",
      " 23.912289 seconds (7.36 M allocations: 262.956 MiB, 0.26% gc time, 0.75% compilation time)\n",
      " 23.836656 seconds (7.12 M allocations: 246.293 MiB, 0.19% gc time)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to collect(map(...)).\")\n",
    "for i in 1:num_runs \n",
    "    @time collect(map(conv_spectrum,lambdas_dist)) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying all that data back for the delegator process to access added a significant amount to the total time.\n",
    "Sometimes you don't actually need to bring all the data back to the delegator process.  For example, you might have several calculations that can be done, each leaving the data distributed across many workers, until the very end.  We'll demonstrate that next.\n",
    "\n",
    "Imagine that we only wanted to compute the total flux within a filter bandpass (i.e., range of wavelengths).  Then we could write a function that determine each wavelength is inside the filter bandpass.  Then each worker could use that function to determine which points fall within the filter and return only the summed flux to reduce the amount of communications overhead.\n",
    "\n",
    "First, we'll want to tell each worker process what range of wavelengths to sum over.  To simplify the syntax, I'm using the [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl) package's `sendto` function to explictly send data from the delegator to each of the worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sendto(workers(), lambda_min=lambda_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sendto(workers(), lambda_max=lambda_min+100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that different processors can have different values stored in the same variable name.  For example above, we send `lambda_max` on the worker process to a different value than on the delegator process, as verified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@getfrom first(workers()) lambda_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes that can be helpful (i.e., each worker can process data using its own variables without interfereing with other processes).  But sometimes that can be create confusion and bugs.  It's very easy to write bugs when using unconstrained parallel programming.  \n",
    "\n",
    "In order to ease the development, debugging and maintance of parallel code, it's best to use common patterns when possible. \n",
    "For example, one common scenario is that you want to performing a task that can be phrased as a [`mapreduce`](https://en.wikipedia.org/wiki/MapReduce) programming pattern.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function on each of the workers\n",
    "@everywhere is_in_filter_band(x) = (lambda_min::Float64 < x < lambda_max::Float64) ? one(x) : zero(x)\n",
    "\n",
    "# Run mapreduce, summing the product of the convolved spectrum and the filter's weight at each wavelength\n",
    "mapreduce(x->is_in_filter_band(x)*conv_spectrum(x), +, lambdas_dist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:32.528000-05:00",
     "start_time": "2019-02-25T07:17:40.172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce.\n",
      " 16.046967 seconds (99.59 k allocations: 6.575 MiB, 0.46% compilation time)\n",
      " 15.966189 seconds (1.27 k allocations: 66.800 KiB, 0.03% compilation time)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to mapreduce.\")\n",
    "for i in 1:num_runs \n",
    "    @time mapreduce(x->is_in_filter_band(x)*conv_spectrum(x), +, lambdas_dist) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output (without interfering with output from other jobs)\n",
    "Below, we'll demonstrate how to write the results to a file, making sure that different jobs don't overwrite each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:49.937000-05:00",
     "start_time": "2019-02-25T07:17:40.174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ex2_out_6079270.csv\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = collect(map(conv_spectrum,lambdas_dist)) \n",
    "\n",
    "output_filename = \"ex2_out.csv\"\n",
    "if haskey(ENV,\"SLURM_JOB_ID\")         # see if PBS_JOBID is among environment variables\n",
    "   jobid_num = ENV[\"SLURM_JOB_ID\"]\n",
    "   output_filename = \"ex2_out_\" * jobid_num * \".csv\"\n",
    "end\n",
    "CSV.write(output_filename,DataFrame(lambda=lambdas,result=results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking performance versus number of workers\n",
    "To see how the performance scales on the number of workers, we'll gradually remove worker processes and compare the performance of one of our functions to compute the mean squared error between two spectra from Lab 6, exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function calc_mse_mapreduce(lambdas::AbstractArray, spec1::AbstractSpectrum, spec2::AbstractSpectrum,  v::Number)\n",
    "    c = lab7.speed_of_light\n",
    "    z = v/c \n",
    "    spec2_shifted = doppler_shifted_spectrum(spec2,z)\n",
    "    mse = mapreduce(x->(spec1(x)-spec2_shifted(x))^2, +, lambdas)\n",
    "    mse /= length(lambdas)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31.849789 seconds (260.90 k allocations: 17.439 MiB, 0.53% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.214815167990631e-10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force function to compile\n",
    "@time calc_mse_mapreduce(lambdas_dist, conv_spectrum, conv_spectrum, 10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce on DArray with 1 workers.\n",
      "31.555445933 seconds.\n"
     ]
    }
   ],
   "source": [
    "num_workers_all = nworkers()\n",
    "wall_time = zeros(num_workers_all)\n",
    "for nw in num_workers_all:-1:1\n",
    "    println(\"# Timing calls to mapreduce on DArray with $nw workers.\")\n",
    "    wall_time[nw] = @elapsed calc_mse_mapreduce(lambdas_dist, conv_spectrum, conv_spectrum, 10.0) \n",
    "    println(wall_time[nw], \" seconds.\")\n",
    "    if nw > 1\n",
    "        rmprocs(last(workers()))            # Remove one worker\n",
    "        global lambdas_dist = distribute(lambdas)  # Redistribute wavelengths over remaining workers\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(At this point we've removed the worker processes.  If you want to run things in parallel, you'll need to restart the notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce (serial).\n",
      " 32.371378 seconds (68.23 M allocations: 5.285 GiB, 1.94% gc time, 0.31% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.214815167990631e-10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"# Timing calls to mapreduce (serial).\")\n",
    "@time calc_mse_mapreduce(lambdas, conv_spectrum, conv_spectrum, 10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
