{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astro 528, Lab 7, Exercise 2\n",
    "## Parallelization for Cluster using Distributed-Memory Model\n",
    "\n",
    "In this lab exercise, we'll perform the calculations very similar to those of exercise 2 of lab 5.  However, instead of using a multi-core workstation, we will [run the calculations on the ICDS Roar ACI-B cluster](https://ics.psu.edu/computing-services/ics-aci-user-guide/#07-00-running-jobs-on-aci-b) using a distributed memory model.  \n",
    "\n",
    "You're welcome to run this notebook one cell at a time as in other labs to see how it works.  However, the main point of this lab is to see how to run such a calculation in parallel over multiple processor cores that are not necessarily on the same processor.  Therefore, you'll use the command line interface to submit the jobs [ex2.pbs](https://github.com/PsuAstro528/lab6-start/blob/main/ex2.pbs).  Follow the instructions in the [lab's README](https://github.com/PsuAstro528/lab6-start/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:42.438000-05:00",
     "start_time": "2019-02-25T07:17:40.141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "# Just in case you're running this from JupyterLab\n",
    "using Pkg\n",
    "Pkg.UPDATED_REGISTRY_THIS_SESSION[] = true   \n",
    "Pkg.activate(\".\")\n",
    "# Shouldn't need to instantiate the project, since \n",
    "# you'll have already run as part of exercise 1.\n",
    "# Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, packages are installed to disk and the Roar nodes all see the same file systems, so you only want to run `instantiate` once on the delegator process.\n",
    "\n",
    "### Getting setup for parallel computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the CSV and DataFrames packages that only need to be loaded by the delegator process.\n",
    "Then we'll load Julia's `Distributed` module that provides much of the needed functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:49.984000-05:00",
     "start_time": "2019-02-25T07:17:40.143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Julia is using 1 workers.\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames\n",
    "using Distributed\n",
    "println(\"# Julia is using \", nworkers(), \" workers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:55.974000-05:00",
     "start_time": "2019-02-25T07:17:40.145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Now Julia is using 3 workers.\n"
     ]
    }
   ],
   "source": [
    "# Uncomments the line below, if you're running manually in a notebook and want to test with multiple processors.\n",
    "if haskey(ENV,\"PBS_NODEFILE\") && (nworkers() == 1)\n",
    "    procs_assigned = countlines(ENV[\"PBS_NODEFILE\"])\n",
    "    addprocs(procs_assigned)\n",
    "end\n",
    "println(\"# Now Julia is using \", nworkers(), \" workers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages and modules\n",
    "\n",
    "Now, we can start loading other packages that we'll be using.  Since we want the packages to be in scope on each worker, then we need to add the @everywhere macro in front of the using statement.  Before we can do that we need to activate the project on each of the workers, so they know that they can use the packages in Project.toml.  We don't need to install or instantiate on each worker, since those write files to disk and all the workers have access to the same filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:17:58.903000-05:00",
     "start_time": "2019-02-25T07:17:40.148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n",
      "      From worker 2:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n",
      "      From worker 5:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n",
      "      From worker 4:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `/storage/home/e/ebf11/Teach/Astro528/Fall2021/lab7-dev/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "@everywhere using Pkg\n",
    "@everywhere Pkg.UPDATED_REGISTRY_THIS_SESSION[] = true   # Tell Julia package manager not to download an updated registry for\n",
    "@everywhere Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:01.598000-05:00",
     "start_time": "2019-02-25T07:17:40.150Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere using Distributions\n",
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, I've written several functions that will be used to generate simulated spectra.  This serves a couple of purposes.\n",
    "First, you'll use the code in the exercise, so you have a calculation that's big enough to be worth parallelizing.  For the purposes of this exercise, it's not essential that you review the code I provided in `.jl` files.  However, the second purpose of providing this is to demonstrate several of the programming patterns that we've discussed in class.  For example, the code in the `lab7` module\n",
    "- is in the form of several small functions, each which does one specific task.  \n",
    "- has been moved out of the Jupyter notebook and into `.jl` files in the `src` directory.\n",
    "- creates objects to represent spectra and a convolution kernel.\n",
    "- uses [abstract types](https://docs.julialang.org/en/v1/manual/types/#Abstract-Types-1) and [parametric types](https://docs.julialang.org/en/v1/manual/types/#Parametric-Types-1), so as to create type-stable functions. \n",
    "- has been  put into a Julia [module](https://docs.julialang.org/en/v1/manual/modules/index.html), so that it can be easily loaded and so as to limit potential for namespace conflicts.\n",
    "\n",
    "You don't need to read all of this code right now.  But, when you're writing code for your class project, you're likely to want to make use of some of these same programming patterns. So, it may be useful to refer back to this code later to help see examples of how to apply these design patterns in practice.  \n",
    "        \n",
    "For now, let's include just the file that has the code for the `lab7` module.  `src/lab7.jl` includes the code from the other files.  We'll preface it with `@everywhere`, since we want all of the processors to be able to make use of these function and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.022000-05:00",
     "start_time": "2019-02-25T07:17:40.153Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere include(\"src/lab7.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll bring that module into scope.  Note that since this is not a package, we need to include a `.` to tell Julia that it can the module in the current namespace, rather than needing to load a package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.023000-05:00",
     "start_time": "2019-02-25T07:17:40.155Z"
    }
   },
   "outputs": [],
   "source": [
    "@everywhere using .lab7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data to be analyzed\n",
    "In this exercise, we're going to create a model spectrum consisting of continuum, stellar absorption lines, telluric absorption lines.  \n",
    "The `lab7` module provides a `SimulatedSpectrum` type, but we'll need to initialize a variable with some specific parameter values.  The function does that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:03.506000-05:00",
     "start_time": "2019-02-25T07:17:40.157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_spectrum_object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Create an object that provides a model for the raw spetrum (i.e., before entering the telescope)\"\n",
    "function make_spectrum_object(;lambda_min = 4500, lambda_max = 7500, flux_scale = 1.0,\n",
    "        num_star_lines = 200, num_telluric_lines = 100, limit_line_effect = 10.0)\n",
    "\n",
    "    continuum_param = flux_scale .* [1.0, 1e-5, -2e-8]\n",
    "    \n",
    "    star_line_locs = rand(Uniform(lambda_min,lambda_max),num_star_lines)\n",
    "    star_line_widths = fill(1.0,num_star_lines)\n",
    "    star_line_depths = rand(Uniform(0,1.0),num_star_lines)\n",
    "    \n",
    "    telluric_line_locs = rand(Uniform(lambda_min,lambda_max),num_telluric_lines)\n",
    "    telluric_line_widths = fill(0.2,num_telluric_lines)\n",
    "    telluric_line_depths = rand(Uniform(0,0.4),num_telluric_lines)\n",
    "\n",
    "    SimulatedSpectrum(star_line_locs,star_line_widths,star_line_depths,telluric_line_locs,telluric_line_widths,telluric_line_depths,continuum_param=continuum_param,lambda_mid=0.5*(lambda_min+lambda_max),limit_line_effect=limit_line_effect)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we: \n",
    "1. create a set of wavelengths to observe the spectrum at, \n",
    "2. call the function above to create a spectrum object, \n",
    "3. create an object containing a model for the point spread function, and \n",
    "4. create an object that can compute the convolution of our spectral model with the point spread function model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:05.032000-05:00",
     "start_time": "2019-02-25T07:17:40.159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolvedSpectrum{SimulatedSpectrum{Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}, GaussianMixtureConvolutionKernel{Float64, Float64}}(SimulatedSpectrum{Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64, Float64}([7123.2510334783165, 5483.477760805866, 6002.334435093768, 5767.2602747386745, 4557.4841698580585, 7203.671475375378, 7188.214672625796, 6182.495092613661, 6756.312359577489, 5079.533171064807  …  5950.613911593, 7215.595997924973, 5644.09105598876, 4861.282685818973, 6265.536872447527, 4603.201599635212, 5736.856545764558, 5415.761778383482, 4535.143387027149, 4921.1540830707545], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.9626911949875838, 0.8582260649562032, 0.09909292288325733, 0.49778039972922183, 0.9307830758410467, 0.5796482138470056, 0.7969162316211942, 0.00038276100656609024, 0.3319896557249724, 0.6473685409780343  …  0.46940150269793524, 0.5915438785045373, 0.26554103505058246, 0.21547995824726573, 0.5916562973527535, 0.18950945279813536, 0.621370296145296, 0.883518420170353, 0.8396778124391393, 0.18655715056060873], [6790.030016168501, 5424.673798693506, 6552.566907641186, 5822.254274436075, 6463.146255039679, 6082.786216326202, 6304.355145778474, 6619.047392515804, 7005.277329384087, 6448.1727965931  …  5325.365832405829, 7067.401553851507, 6470.011455797939, 4662.1324385247535, 7393.45370229318, 4782.194194030556, 7441.219473805382, 4994.953183061146, 6723.598859354341, 7275.77605978033], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2  …  0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], [0.3090182947987029, 0.13513866692697407, 0.2159659655145787, 0.36479419366249755, 0.33646001629263367, 0.37741358825281424, 0.050132223614425535, 0.30734524812326147, 0.22572306750288887, 0.25006478515207275  …  0.16284216051309797, 0.36265158662722236, 0.36723781159486574, 0.09704912601952592, 0.3461012856126902, 0.3058643382836664, 0.3303325573785322, 0.2597341511611779, 0.34778755721342486, 0.18426104880980543], [1.0, 1.0e-5, -2.0e-8], 0.0, 6000.0, 10.0), GaussianMixtureConvolutionKernel{Float64, Float64}(Normal{Float64}[Normal{Float64}(μ=0.0, σ=0.5), Normal{Float64}(μ=0.0, σ=1.0), Normal{Float64}(μ=0.0, σ=2.0)], [0.8, 0.15, 0.05], 1.0000000143325827, 10.0), 10.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.  Pick range of of wavelength to work on.\n",
    "lambda_min = 4500\n",
    "lambda_max = 7500\n",
    "# You may want to adjust the num_lambda to make things more/less computationally intensive\n",
    "num_lambda = 128*1024\n",
    "lambdas = collect(range(lambda_min,stop=lambda_max, length=num_lambda));\n",
    "\n",
    "# 2.  Create a model  spectrum that we'll analyze below\n",
    "raw_spectrum = make_spectrum_object(lambda_min=lambda_min,lambda_max=lambda_max)\n",
    "\n",
    "# 3.  Create a model for the point spread function (PSF)\n",
    "psf_widths  = [0.5, 1.0, 2.0]\n",
    "psf_weights = [0.8, 0.15, 0.05]\n",
    "psf_model = GaussianMixtureConvolutionKernel(psf_widths,psf_weights)\n",
    "\n",
    "# 4. Create a model for the the convolution of thte raw spectrum with the PDF model\n",
    "conv_spectrum = ConvolvedSpectrum(raw_spectrum,psf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking serial code\n",
    "\n",
    "*If the current job has just one worker process,* then we'll benchmark the calculation of this spectrum on a single processor.  Based on performance results from lab 5, we'll make use of Julia's [dot syntax](https://docs.julialang.org/en/v1/manual/functions/#man-vectorized-1) to [\"broadcast\" and \"fuse\"](https://docs.julialang.org/en/v1/base/arrays/#Broadcast-and-vectorization-1) the array operation.    We'll run it just a few times (rather than using `@btime`).\n",
    "Since the rest of the notebook is meant for distributed computing, we'll tell it to exit here if there's only a single worker.  Before we do, we'll flush the buffer, so any messages are written to `STDOUT` before the kernel exits.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:05.217000-05:00",
     "start_time": "2019-02-25T07:17:40.160Z"
    }
   },
   "outputs": [],
   "source": [
    "num_runs = 3\n",
    "if nworkers() == 1    \n",
    "    for i in 1:num_runs @time conv_spectrum.(lambdas); end\n",
    "    flush(stdout) # flush buffer before the kernel exits\n",
    "    sleep(1)      # wait for one second just to make sure\n",
    "    exit(0)       # Exit the script since completed serial calculation\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this in a Jupyter notebook and got a message about the kernel dieing, don't worry.  We used the `exit` command to cause the julia kernel to exit.  If you're in the notebook server and want to keep going, then you can rerun the previous cells above, and either add some processors (e.g., `addprocs(4)`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Arrays\n",
    "Here, we want to spread the work over processor cores than are not necessarily on the same node, so we need to use a [distributed memory system](https://en.wikipedia.org/wiki/Distributed_memory).  This would be necessary if you wanted your job to run on more cores than are available on a single node.  It could also be useful if you wanted to increase the chances that the scheduler starts your job more quickly, since asking for several processors cores that don't need to be on the same node is easier to accommodate than asking for the same number of cores on a single node.  Here we'll use Julia's [DistributedArrays.jl](https://juliaparallel.github.io/DistributedArrays.jl/latest/index.html) package to make programming for distributed memory systems relatively easy.  \n",
    "\n",
    "Here we'll create a distributed array by simply applying `distribute` to our existing array of wavelengths.  (Remember that we could initialize a `DArray` more efficiently be letting each workers initializes its own data.  For convenience functions like `dzeros`, `dones`, `drand`, `drandn` and `dfill` act similarly to their counterparts without a `d` prefix, but create DArrays instead of regular Arrays.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:07.340000-05:00",
     "start_time": "2019-02-25T07:17:40.163Z"
    }
   },
   "outputs": [],
   "source": [
    "lambdas_dist = distribute(lambdas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first time we call a function, it takes some extra time and memory to compile it.  So let's do that again, this time benchmarking the `distribute` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:18:07.393000-05:00",
     "start_time": "2019-02-25T07:17:40.165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to distribute.\n",
      "  0.001078 seconds (546 allocations: 1.025 MiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to distribute.\")\n",
    "@time lambdas_dist = distribute(lambdas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will apply `map` to a `lambda_dist`, which is a `DArray`.  `map` will parallelize the calculation and return the results in a `DArray`.  Each worker operates on the subset of the array that is local to that worker process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:09.082000-05:00",
     "start_time": "2019-02-25T07:17:40.167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to map(...).\n",
      "  9.338440 seconds (1.99 M allocations: 124.369 MiB, 0.35% gc time, 3.58% compilation time)\n",
      "  6.446841 seconds (1.01 k allocations: 85.938 KiB)\n",
      "  6.385849 seconds (995 allocations: 85.031 KiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to map(...).\")\n",
    "for i in 1:num_runs \n",
    "    @time map(conv_spectrum,lambdas_dist) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we left the results with the workers, rather than copying the results back to the delegator process.\n",
    "In the cell below, we will call `collect` the data in order to copy all the data back to to the delegator process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:09.082000-05:00",
     "start_time": "2019-02-25T07:17:40.167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to collect(map(...)).\n",
      " 16.337607 seconds (8.44 M allocations: 291.844 MiB, 0.59% gc time, 1.21% compilation time)\n",
      " 15.814595 seconds (7.90 M allocations: 259.293 MiB, 0.34% gc time)\n",
      " 15.987923 seconds (7.90 M allocations: 259.293 MiB, 0.30% gc time)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to collect(map(...)).\")\n",
    "for i in 1:num_runs \n",
    "    @time collect(map(conv_spectrum,lambdas_dist)) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying all that data back for the delegator process to access added a significant amount to the total time.\n",
    "Sometimes you don't actually need to bring all the data back to the delegator process.  For example, you might have several calculations that can be done, each leaving the data distributed across many workers, until the very end.\n",
    "Another common scenario is that you want to performing a task that can be phrased as a [`mapreduce`](https://en.wikipedia.org/wiki/MapReduce) programming pattern.  For example, imagine that we only wanted to compute the total flux over a filter band.  Then we could use code like the following to reduce the amount of communications overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:16.177000-05:00",
     "start_time": "2019-02-25T07:17:40.170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Send the value lambda_min to each of the workers\n",
    "for p in workers() remotecall_fetch(()->lambda_min, p); end\n",
    "\n",
    "# Define a function on each of the workers\n",
    "@everywhere is_in_filter_band(x) = (lambda_min < x < lambda_min+100) ? one(x) : zero(x)\n",
    "\n",
    "# Run mapreduce, summing the product of the convolved spectrum and the filter's weight at each wavelength\n",
    "mapreduce(x->is_in_filter_band(x)*conv_spectrum(x), +, lambdas_dist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:32.528000-05:00",
     "start_time": "2019-02-25T07:17:40.172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce.\n",
      "  6.537715 seconds (229.88 k allocations: 14.220 MiB, 1.66% compilation time)\n",
      "  6.360973 seconds (647 allocations: 30.016 KiB)\n",
      "  6.370328 seconds (645 allocations: 29.672 KiB)\n"
     ]
    }
   ],
   "source": [
    "println(\"# Timing calls to mapreduce.\")\n",
    "for i in 1:num_runs \n",
    "    @time mapreduce(x->is_in_filter_band(x)*conv_spectrum(x), +, lambdas_dist) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output (without interfering with output from other jobs)\n",
    "Below, we'll demonstrate how to write the results to a file, making sure that different jobs don't overwrite each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T02:19:49.937000-05:00",
     "start_time": "2019-02-25T07:17:40.174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ex2_out_31282870.csv\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = collect(map(conv_spectrum,lambdas_dist)) \n",
    "\n",
    "output_filename = \"ex2_out.csv\"\n",
    "if haskey(ENV,\"PBS_JOBID\")         # see if PBS_JOBID is among environment variables\n",
    "  m = match(r\"^(\\d+\\[?\\d*\\]?)\\.\",ENV[\"PBS_JOBID\"])  # \n",
    "  if m != nothing               \n",
    "      jobid_num = m.captures[1]\n",
    "      output_filename = \"ex2_out_\" * jobid_num * \".csv\"\n",
    "  end\n",
    "end\n",
    "CSV.write(output_filename,DataFrame(lambda=lambdas,result=results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking performance versus number of workers\n",
    "To see how the performance scales on the number of workers, we'll gradually remove worker processes and compare the performance of one of our functions to compute the mean squared error between two spectra from Lab 6, exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function calc_mse_mapreduce(lambdas::AbstractArray, spec1::AbstractSpectrum, spec2::AbstractSpectrum,  v::Number)\n",
    "    c = lab7.speed_of_light\n",
    "    z = v/c \n",
    "    spec2_shifted = doppler_shifted_spectrum(spec2,z)\n",
    "    mse = mapreduce(x->(spec1(x)-spec2_shifted(x))^2, +, lambdas)\n",
    "    mse /= length(lambdas)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13.385179 seconds (2.48 M allocations: 147.236 MiB, 0.25% gc time, 3.99% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.651876722818536e-10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force function to compile\n",
    "@time calc_mse_mapreduce(lambdas_dist, conv_spectrum, conv_spectrum, 10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce on DArray with 4 workers.\n",
      " 12.765890 seconds (1.11 k allocations: 89.297 KiB)\n",
      "# Timing calls to mapreduce on DArray with 3 workers.\n",
      " 16.429501 seconds (1.08 k allocations: 76.000 KiB)\n",
      "# Timing calls to mapreduce on DArray with 2 workers.\n",
      " 23.167735 seconds (1.14 k allocations: 65.141 KiB)\n",
      "# Timing calls to mapreduce on DArray with 1 workers.\n",
      " 46.522344 seconds (1.72 k allocations: 69.672 KiB)\n"
     ]
    }
   ],
   "source": [
    "num_workers_all = nworkers()\n",
    "for nw in num_workers_all:-1:1\n",
    "    println(\"# Timing calls to mapreduce on DArray with $nw workers.\")\n",
    "    @time calc_mse_mapreduce(lambdas_dist, conv_spectrum, conv_spectrum, 10.0) \n",
    "    if nw > 1\n",
    "        rmprocs(last(workers()))            # Remove one worker\n",
    "        lambdas_dist = distribute(lambdas)  # Redistribute wavelengths over remaining workers\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Timing calls to mapreduce (serial).\n",
      " 43.114487 seconds (119.16 M allocations: 8.323 GiB, 3.39% gc time, 2.77% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.651876722818536e-10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"# Timing calls to mapreduce (serial).\")\n",
    "@time calc_mse_mapreduce(lambdas, conv_spectrum, conv_spectrum, 10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
